#!/usr/bin/env python3
"""
SafeGround AI - evalNm íŒŒì‹± í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

API-7ì˜ evalNm (í‰ê°€ëª…) í•„ë“œì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:
- ì‹œë„(city) ì¶”ì¶œ ì„±ê³µë¥ 
- ì‹œêµ°êµ¬(district) ì¶”ì¶œ ì„±ê³µë¥ 
- ìë©´ë™(dong) ì¶”ì¶œ ì„±ê³µë¥ 

ëª©í‘œ: 70% ì´ìƒ íŒŒì‹± ì„±ê³µ â†’ ì „ì²´ ìˆ˜ì§‘ GO
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Tuple
from collections import Counter

# ë°ì´í„° ì €ì¥ ê²½ë¡œ
DATA_DIR = Path("data/sample")

# ì„œìš¸ì‹œ í–‰ì •ë™ ë°ì´í„° ë¡œë“œ
SEOUL_DONG_FILE = Path("data/seoul_424dong.csv")


def load_seoul_dongs() -> Dict[str, List[str]]:
    """
    ì„œìš¸ì‹œ 424ê°œ í–‰ì •ë™ ë°ì´í„° ë¡œë“œ

    Returns:
        {
            'êµ¬': ['ë™1', 'ë™2', ...],
            ...
        }
    """
    dongs_by_district = {}

    if not SEOUL_DONG_FILE.exists():
        print(f"âœ— í–‰ì •ë™ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {SEOUL_DONG_FILE}")
        return {}

    with open(SEOUL_DONG_FILE, 'r', encoding='utf-8') as f:
        lines = f.readlines()[1:]  # Skip header

    for line in lines:
        parts = line.strip().split(',')
        if len(parts) >= 3:
            district = parts[1]  # êµ¬
            dong = parts[2]      # ë™

            if district not in dongs_by_district:
                dongs_by_district[district] = []

            dongs_by_district[district].append(dong)

    print(f"âœ“ ì„œìš¸ì‹œ í–‰ì •ë™ ë°ì´í„° ë¡œë“œ: {len(dongs_by_district)}ê°œ êµ¬")
    return dongs_by_district


def extract_location_from_evalNm(eval_nm: str, seoul_dongs: Dict[str, List[str]]) -> Dict[str, str]:
    """
    evalNmì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (íœ´ë¦¬ìŠ¤í‹±)

    Args:
        eval_nm: í‰ê°€ëª… (ì˜ˆ: "í¬ì²œë™ì„±ë‚¨ì‹œíƒ„ë¦¬(1,2ê³µì‚¬) í–¥í›„ê³„íšì„œì˜ ì„¤ì¹˜ê³µì‚¬")
        seoul_dongs: ì„œìš¸ì‹œ í–‰ì •ë™ ë”•ì…”ë„ˆë¦¬

    Returns:
        {
            'city': 'ì„œìš¸íŠ¹ë³„ì‹œ',
            'district': 'ê°•ë‚¨êµ¬',
            'dong': 'ì—­ì‚¼ë™',
            'confidence': 'high/medium/low'
        }
    """
    location = {
        'city': None,
        'district': None,
        'dong': None,
        'confidence': 'low'
    }

    # íŒ¨í„´ ì •ì˜
    city_pattern = r'(ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…)'
    district_pattern = r'([ê°€-í£]+êµ¬)'
    dong_pattern = r'([ê°€-í£]+ë™|[ê°€-í£]+ì|[ê°€-í£]+ë©´)'

    # 1. ì‹œë„ ì¶”ì¶œ
    city_match = re.search(city_pattern, eval_nm)
    if city_match:
        city = city_match.group(1)
        if city == 'ì„œìš¸':
            location['city'] = 'ì„œìš¸íŠ¹ë³„ì‹œ'
        else:
            location['city'] = city

    # 2. ì‹œêµ°êµ¬ ì¶”ì¶œ (ì„œìš¸ì‹œ êµ¬ ìš°ì„ )
    district_matches = re.findall(district_pattern, eval_nm)
    if district_matches:
        # ì„œìš¸ì‹œ êµ¬ì¸ì§€ í™•ì¸
        for district in district_matches:
            if district in seoul_dongs:
                location['district'] = district
                location['city'] = 'ì„œìš¸íŠ¹ë³„ì‹œ'  # ì„œìš¸ì‹œ êµ¬ ë°œê²¬ ì‹œ cityë„ ì—…ë°ì´íŠ¸
                break

        # ì„œìš¸ì‹œ êµ¬ê°€ ì•„ë‹ˆë©´ ì²« ë²ˆì§¸ ë§¤ì¹˜
        if not location['district']:
            location['district'] = district_matches[0]

    # 3. ìë©´ë™ ì¶”ì¶œ
    dong_matches = re.findall(dong_pattern, eval_nm)
    if dong_matches and location['district']:
        # í•´ë‹¹ êµ¬ì˜ ë™ ë¦¬ìŠ¤íŠ¸ í™•ì¸
        valid_dongs = seoul_dongs.get(location['district'], [])

        for dong in dong_matches:
            if dong in valid_dongs:
                location['dong'] = dong
                location['confidence'] = 'high'
                break

        # ìœ íš¨í•œ ë™ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë§¤ì¹˜
        if not location['dong'] and dong_matches:
            location['dong'] = dong_matches[0]
            location['confidence'] = 'medium'

    # ì‹ ë¢°ë„ ì¡°ì •
    if location['city'] and location['district'] and location['dong']:
        if location['confidence'] != 'high':
            location['confidence'] = 'medium'
    elif location['city'] or location['district']:
        location['confidence'] = 'low'

    return location


def test_parsing_on_samples(eval_names: List[str], seoul_dongs: Dict[str, List[str]]) -> Dict:
    """
    ìƒ˜í”Œ evalNm ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹± í…ŒìŠ¤íŠ¸

    Args:
        eval_names: evalNm ë¦¬ìŠ¤íŠ¸
        seoul_dongs: ì„œìš¸ì‹œ í–‰ì •ë™ ë”•ì…”ë„ˆë¦¬

    Returns:
        íŒŒì‹± ê²°ê³¼ í†µê³„
    """
    results = []

    print("\n" + "="*80)
    print("ğŸ§ª evalNm íŒŒì‹± í…ŒìŠ¤íŠ¸")
    print("="*80)

    for idx, eval_nm in enumerate(eval_names, 1):
        location = extract_location_from_evalNm(eval_nm, seoul_dongs)

        result = {
            'eval_nm': eval_nm,
            'city': location['city'],
            'district': location['district'],
            'dong': location['dong'],
            'confidence': location['confidence']
        }
        results.append(result)

        # ì¶œë ¥
        city_str = location['city'] or 'âœ—'
        district_str = location['district'] or 'âœ—'
        dong_str = location['dong'] or 'âœ—'
        confidence_str = location['confidence']

        print(f"\n[{idx}] {eval_nm}")
        print(f"  â†’ ì‹œë„: {city_str}")
        print(f"  â†’ êµ¬:   {district_str}")
        print(f"  â†’ ë™:   {dong_str}")
        print(f"  â†’ ì‹ ë¢°ë„: {confidence_str}")

    return results


def calculate_success_rate(results: List[Dict]) -> Dict:
    """
    íŒŒì‹± ì„±ê³µë¥  ê³„ì‚°

    Returns:
        {
            'city_rate': 0.8,
            'district_rate': 0.7,
            'dong_rate': 0.6,
            'overall_rate': 0.5
        }
    """
    total = len(results)

    if total == 0:
        return {
            'city_rate': 0.0,
            'district_rate': 0.0,
            'dong_rate': 0.0,
            'overall_rate': 0.0
        }

    city_success = sum(1 for r in results if r['city'])
    district_success = sum(1 for r in results if r['district'])
    dong_success = sum(1 for r in results if r['dong'])
    overall_success = sum(1 for r in results if r['city'] and r['district'] and r['dong'])

    return {
        'city_rate': city_success / total * 100,
        'district_rate': district_success / total * 100,
        'dong_rate': dong_success / total * 100,
        'overall_rate': overall_success / total * 100
    }


def generate_parsing_report(results: List[Dict], success_rates: Dict):
    """íŒŒì‹± í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
    print("\n" + "ğŸ¯"*40)
    print("ğŸ“Š evalNm íŒŒì‹± í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸")
    print("ğŸ¯"*40)

    total = len(results)

    print(f"\n1ï¸âƒ£ íŒŒì‹± ì„±ê³µë¥  (ì´ {total}ê±´)")
    print("="*60)
    print(f"  ì‹œë„(city)   ì¶”ì¶œ: {success_rates['city_rate']:>6.1f}%")
    print(f"  ì‹œêµ°êµ¬(district) ì¶”ì¶œ: {success_rates['district_rate']:>6.1f}%")
    print(f"  ìë©´ë™(dong) ì¶”ì¶œ: {success_rates['dong_rate']:>6.1f}%")
    print(f"  ì „ì²´(city+district+dong): {success_rates['overall_rate']:>6.1f}%")

    # ì‹ ë¢°ë„ ë¶„í¬
    confidence_counts = Counter(r['confidence'] for r in results)
    print(f"\n2ï¸âƒ£ ì‹ ë¢°ë„ ë¶„í¬")
    print("="*60)
    for conf in ['high', 'medium', 'low']:
        count = confidence_counts.get(conf, 0)
        ratio = count / total * 100 if total > 0 else 0
        print(f"  {conf:>8}: {count:>3}ê±´ ({ratio:>5.1f}%)")

    # íŒì •
    print(f"\n3ï¸âƒ£ ì „ì²´ ìˆ˜ì§‘ ì—¬ë¶€ íŒì •")
    print("="*60)

    threshold = 70.0
    overall_rate = success_rates['overall_rate']

    if overall_rate >= threshold:
        print(f"  âœ… í•©ê²©! íŒŒì‹± ì„±ê³µë¥  {overall_rate:.1f}% >= {threshold}%")
        print(f"  âœ… ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì§„í–‰ ê¶Œì¥")
        print(f"\n  ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"     1. API-7ë¡œ ì „ì²´ í‰ê°€ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘")
        print(f"     2. evalNm íŒŒì‹±ìœ¼ë¡œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ")
        print(f"     3. 424ê°œ í–‰ì •ë™ ë§¤í•‘")
    else:
        print(f"  âš ï¸  ë¶ˆí•©ê²©. íŒŒì‹± ì„±ê³µë¥  {overall_rate:.1f}% < {threshold}%")
        print(f"  âš ï¸  ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ ì–´ë ¤ì›€")
        print(f"\n  ğŸ“Œ ëŒ€ì•ˆ:")
        print(f"     1. API-13ì˜ dong í•„ë“œ í™œìš© (ì‚¬ê³  ì´ë ¥ ë°ì´í„°)")
        print(f"     2. ì™¸ë¶€ ì£¼ì†Œ API í™œìš© (ë„ë¡œëª…ì£¼ì†Œ â†’ í–‰ì •ë™)")
        print(f"     3. ìˆ˜ì‘ì—… ë§¤í•‘ (ì†ŒëŸ‰ ë°ì´í„°ì¸ ê²½ìš°)")

    # ìƒ˜í”Œ ë°ì´í„° ì €ì¥
    results_file = DATA_DIR / 'parsing_test_results.json'
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'results': results,
            'success_rates': success_rates,
            'total_count': total
        }, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {results_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "ğŸ§ª"*40)
    print("SafeGround AI - evalNm íŒŒì‹± í…ŒìŠ¤íŠ¸")
    print("ëª©í‘œ: 70% ì´ìƒ íŒŒì‹± ì„±ê³µ â†’ ì „ì²´ ìˆ˜ì§‘ GO")
    print("ğŸ§ª"*40)

    # ì„œìš¸ì‹œ í–‰ì •ë™ ë°ì´í„° ë¡œë“œ
    seoul_dongs = load_seoul_dongs()

    # evalNm ìƒ˜í”Œ ë¡œë“œ
    eval_names_file = DATA_DIR / 'eval_names_sample.json'
    if not eval_names_file.exists():
        print(f"\nâœ— evalNm ìƒ˜í”Œ íŒŒì¼ ì—†ìŒ: {eval_names_file}")
        print(f"ë¨¼ì € explore_apis.pyì™€ analyze_sample.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    with open(eval_names_file, 'r', encoding='utf-8') as f:
        eval_names = json.load(f)

    print(f"\nâœ“ evalNm ìƒ˜í”Œ ë¡œë“œ: {len(eval_names)}ê±´")

    # íŒŒì‹± í…ŒìŠ¤íŠ¸
    results = test_parsing_on_samples(eval_names, seoul_dongs)

    # ì„±ê³µë¥  ê³„ì‚°
    success_rates = calculate_success_rate(results)

    # ë¦¬í¬íŠ¸ ìƒì„±
    generate_parsing_report(results, success_rates)

    print("\n" + "="*80)
    print("âœ… íŒŒì‹± í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)


if __name__ == "__main__":
    main()
